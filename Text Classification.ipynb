{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "import pandas, numpy, string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"D:/Program Files/Jupyter/NLP/NLP_raw data\"\n",
    "folders = os.listdir(path)\n",
    "labels, texts = [], []\n",
    "for folder in folders:\n",
    "    curr_path = path +\"/\"+folder\n",
    "    files = os.listdir(curr_path)\n",
    "    for file in files:\n",
    "        f = open(curr_path+\"/\"+file)\n",
    "        iter_f = iter(f)\n",
    "        indic = 0\n",
    "        str=\"\"\n",
    "        for line in iter_f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                line = line.lower()\n",
    "                str = str+line+\" \"\n",
    "                indic = indic+1\n",
    "                # store every five lines as one document\n",
    "                if indic == 5:\n",
    "                    labels.append(folder)\n",
    "                    texts.append(str)\n",
    "                    str=\"\"\n",
    "                    indic=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe using texts and labels\n",
    "trainDF = pandas.DataFrame()\n",
    "trainDF['text'] = texts\n",
    "trainDF['label']=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training and validation datasets \n",
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(trainDF['text'], trainDF['label'], test_size=0.2, shuffle=True)\n",
    "\n",
    "# label encode the target variable \n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "tfidf_vect.fit(trainDF['text'])\n",
    "xtrain_tfidf =  tfidf_vect.transform(train_x)\n",
    "xvalid_tfidf =  tfidf_vect.transform(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of NB for word level tfidf:  0.810246394231\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Classifier\n",
    "nb_classifier = naive_bayes.MultinomialNB()\n",
    "nb_classifier.fit(xtrain_tfidf, train_y)\n",
    "nb_predictions = nb_classifier.predict(xvalid_tfidf)\n",
    "nb_accuracy = metrics.accuracy_score(nb_predictions, valid_y)\n",
    "print(\"Accuracy of NB for word level tfidf: \", nb_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression on word level tfidf:  0.840369591346\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Classifier\n",
    "logic_classifier = linear_model.LogisticRegression()\n",
    "logic_classifier.fit(xtrain_tfidf, train_y)\n",
    "logic_predictions = logic_classifier.predict(xvalid_tfidf)\n",
    "logic_accuracy = metrics.accuracy_score(logic_predictions, valid_y)\n",
    "print(\"Accuracy of logistic regression on word level tfidf: \", logic_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest for word level tfidf:  0.687349759615\n"
     ]
    }
   ],
   "source": [
    "# Bagging (Random Forest)\n",
    "rf_classifier = ensemble.RandomForestClassifier()\n",
    "rf_classifier.fit(xtrain_tfidf, train_y)\n",
    "rf_predictions = rf_classifier.predict(xvalid_tfidf)\n",
    "rf_accuracy = metrics.accuracy_score(rf_predictions, valid_y)\n",
    "print(\"Accuracy of random forest for word level tfidf: \", rf_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngram level tf-idf \n",
    "tfidf_vect_ngram = TfidfVectorizer(stop_words='english', token_pattern=r'\\w{1,}', ngram_range=(1,2), max_features=8000)\n",
    "tfidf_vect_ngram.fit(trainDF['text'])\n",
    "xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_x)\n",
    "xvalid_tfidf_ngram =  tfidf_vect_ngram.transform(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of NB on ngram level tfidf 0.827674278846\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Classifier for ngram level tf-idf \n",
    "nb_classifier = naive_bayes.MultinomialNB()\n",
    "nb_classifier.fit(xtrain_tfidf_ngram, train_y)\n",
    "nb_predictions = nb_classifier.predict(xvalid_tfidf_ngram)\n",
    "nb_accuracy = metrics.accuracy_score(nb_predictions, valid_y)\n",
    "print(\"Accuracy of NB on ngram level tfidf\" , nb_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression on ngram level tfidf 0.860652043269\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Classifier for ngram level tf-idf \n",
    "logic_classifier = linear_model.LogisticRegression()\n",
    "logic_classifier.fit(xtrain_tfidf_ngram, train_y)\n",
    "logic_predictions = logic_classifier.predict(xvalid_tfidf_ngram)\n",
    "logic_accuracy = metrics.accuracy_score(logic_predictions, valid_y)\n",
    "print(\"Accuracy of logistic regression on ngram level tfidf\", logic_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest on ngram level tfidf 0.691105769231\n"
     ]
    }
   ],
   "source": [
    "# Bagging (Random Forest)\n",
    "rf_classifier = ensemble.RandomForestClassifier()\n",
    "rf_classifier.fit(xtrain_tfidf_ngram, train_y)\n",
    "rf_predictions = rf_classifier.predict(xvalid_tfidf_ngram)\n",
    "rf_accuracy = metrics.accuracy_score(rf_predictions, valid_y)\n",
    "print(\"Accuracy of random forest on ngram level tfidf\", rf_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Implementation of SVM \"\"\"\n",
    "# SVM would use lot of computational resources if we don't trim features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "own_dictionary=[]\n",
    "def feature_extraction():\n",
    "    # a) Read all the books that belong to one author into a single string\n",
    "    path = \"D:/Program Files/Jupyter/NLP/NLP_raw data\"\n",
    "    folders = os.listdir(path)\n",
    "    labels, texts = [], []\n",
    "    for folder in folders:\n",
    "        curr_path = path +\"/\"+folder\n",
    "        files = os.listdir(curr_path)\n",
    "        string=\"\"\n",
    "        indic =0\n",
    "        for file in files:\n",
    "            indic=indic+1\n",
    "            if indic==3:\n",
    "                break;\n",
    "            f = open(curr_path+\"/\"+file)\n",
    "            iter_f = iter(f)\n",
    "            for line in iter_f:\n",
    "                line = line.strip()\n",
    "                if line:\n",
    "                    line = line.lower()\n",
    "                    string = string+line+\" \"\n",
    "        texts.append(string)\n",
    "        labels.append(folder)\n",
    "    # b) select the most important features( features exists in at least four categories\n",
    "# and frequency gap between the largest one and the fourth largest one to be more \n",
    "# than 0.02\n",
    "tfidf_vect = TfidfVectorizer(stop_words='english')\n",
    "tfidf = tfidf_vect.fit_transform(texts)\n",
    "features = tfidf_vect.vocabulary_    \n",
    "    d={}\n",
    "    for i in range(10):\n",
    "        for word in features:\n",
    "            tfidf_w = tfidf[i,features[word]]\n",
    "            if tfidf_w !=0:\n",
    "                if word in d:\n",
    "                    d[word] = numpy.append(d[word], tfidf_w)\n",
    "                else:\n",
    "                    d[word] = numpy.array(tfidf_w)\n",
    "    for word in d:\n",
    "        if d[word].size >= 4:\n",
    "            index = numpy.argsort(d[word])\n",
    "            if float(d[word][index[d[word].size-1]])-float(d[word][index[d[word].size-4]])>0.02:\n",
    "                own_dictionary.append(word)\n",
    "feature_extraction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324\n"
     ]
    }
   ],
   "source": [
    "print(len(own_dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect_svm = TfidfVectorizer(stop_words='english', vocabulary=own_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect_svm.fit(texts)\n",
    "xtrain_tfidf =  tfidf_vect_svm.transform(train_x)\n",
    "xvalid_tfidf =  tfidf_vect_svm.transform(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM on word level tfidf:  0.327824519231\n"
     ]
    }
   ],
   "source": [
    "#train the svm model based on tfidf o\n",
    "svm_classifier = svm.SVC()\n",
    "svm_classifier.fit(xtrain_tfidf, train_y)\n",
    "svm_predictions = svm_classifier.predict(xvalid_tfidf)\n",
    "svm_accuracy = metrics.accuracy_score(svm_predictions, valid_y)\n",
    "print(\"Accuracy of SVM on word level tfidf: \", svm_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53246, 640)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
